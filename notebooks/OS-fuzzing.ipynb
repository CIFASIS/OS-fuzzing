{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using Machine Learning to predict the outcome of a fuzzing campaing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fuzzing campaings can take time, but unfortunately operating systems contain thousands of different binaries that should be tested. Given a very large amount of programs/inputs to fuzz (we call them 'testcases'), in this simple tutorial we are going to see how [VDiscover](http://vdiscover.org/) is used to predict which testcases can be mutated using [zzuf](http://caca.zoy.org/wiki/zzuf) to uncover bugs causing interesting unexpected behaviours like crashes, memory leaks and infinite loops among others."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting started"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before start our fuzzing campaings, it is very important to create a controled enviroment to perform our experiments.\n",
      "We use [Vagrant](http://vagrantup.com) for managing and accesing virtual machines to perform a fuzzing campains.\n",
      "For our experiments, we started from a [preinstalled Ubuntu image](https://vagrantcloud.com/ubuntu/boxes/trusty32). For this experiments, we are selected the 32-bit version of Ubuntu since the [x86-64 support of VDiscover is not ready yet](https://github.com/CIFASIS/VDiscover/issues/2). A base Ubuntu 14.04 virtual machine can be fetch executing:\n",
      "\n",
      "    $ vagrant init ubuntu/trusty32\n",
      "$ vagrant up --provider virtualbox\n",
      "\n",
      "Now, our brand-new virtual machine can be easily accessed using ssh:\n",
      "\n",
      "    $ vagrant ssh\n",
      "\n",
      "We will analyze only testcases of fully updated binary programs so a complete upgrade of the system is necesary before start: \n",
      "\n",
      "    # apt-get update\n",
      "    # apt-get upgrade\n",
      "    \n",
      "Since the software included in the image is rather basic we will probably wanto include some tools to\n",
      "\n",
      "    # apt-get install poppler-utils vorbis-tools imagemagick graphviz ...\n",
      "    \n",
      "Finally, we need to define where the binaries are located. For example, we can grab binaries to fuzz from the usual directories:\n",
      "\n",
      "    /usr/bin/\n",
      "    /usr/sbin/"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Discovering crashes automatically"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To discover interesting bugs to analyze, we need to define a procedure to extract a command-line testcase. \n",
      "After that, using a suitable input file, a random mutation can be used to detect interesting buggy behaviours. We aim this procedure to collect a large amount of testcases to train a predictor. Therefore we need an end-to-end fully automatic approach. \n",
      "\n",
      "1. **manfuzzer**:\n",
      "\n",
      "  To obtain random command-lines to execute programs we used [manfuzzer](https://github.com/GroundPound/ManFuzzer). This python script produces and executes command-line for fuzzing based on the flags found by running *-h*, *-H*, *--help* and the man page of a program. Our [fork of Manfuzzer](https://github.com/CIFASIS/ManFuzzer/) was modified to allow the generation of command-line testcases using an input file. After selecting a candidate testcase, it will check if the program tries to open the input file. \n",
      "\n",
      "2. **seeds to mutate**\n",
      "  \n",
      "  After we selected a large number of command-line testcases, we can try to mutate different types of input files in order to uncover interesting bugs. Finding a large variety of files to mutate can be a hard task but fortunately the [fuzzing project](https://fuzzing-project.org/) provides a basic but nice [collection of them](https://files.fuzzing-project.org/).\n",
      "    %%Obiously, we issues is that we do not know which seed can be suitable for every program. For instance *pdftotext* will likely produce more interesting results if we mutate a pdf file.\n",
      "\n",
      "3. **zzuf**: \n",
      "\n",
      "  At the last step of this procedure, we used [this widely used multi-purpose fuzzer]() to detect crashes, aborts and other interesting unexpected behavior. Since the fuzzing campaings procedure by zzuf are based on random mutation, it can require thousands of tries to uncover an interesting bug (maybe exposed as a crash). Therefore, in order to obtain interesting results we will fuzz up to $100,000$ times every testcase mutating between $1\\%$ and $50\\%$ of the input files.\n",
      "    \n",
      "Once we extract a very large ammount of testcases to fuzz, we need to run this procedure to collect enough data to train and test a VDiscover predictor. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicting interesting testcases before fuzzing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After we collected and analyzed a large number of testcases, we obtained a dataset contained every testcase and its result after fuzzing it (if it resulted in a interesting behaviour or not). \n",
      "\n",
      "Now we are ready to  start learning from them and predict the outcome of zzuf before even start a fuzzing campaing. To perform a sensible evaluation, it is extremly important to separete our dataset in two disjoint subsets: \n",
      "\n",
      "* A set to train the predictor\n",
      "* A set to test the predictor\n",
      "\n",
      "In order to give\n",
      "\n",
      "\n",
      "\n",
      "After running $20$ independent experiments, the average accuracy results are:\n",
      "\n",
      "* $92\\%$ detecting **non-interesting** testcases\n",
      "* $40\\%$ detecting **interesting** testcases \n",
      "\n",
      "As you can see from the results, the predictor is quite efficient detecting testcases that will waste our time, but not so much with the other ones. Despite such inbalance, VDiscover can be very useful to save our time discarding useless testcases from programs\n",
      "\n",
      "Finally, we can see an example of how the predictor seems to work. In this experiment, from our dataset, we only selected the wget testcases for testing while the rest of the testcases are used in the training. In the testing, we \n",
      "After testing, we summaries the results in the following table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%run srcs/confusion.py\n",
      "table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<center> <table><tr><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;testcase</td><td>predicted</td><td>expected</td></tr><tr><td>/usr/bin/wget:21598</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21558</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21600</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21288</td><td>0</td><td>0</td></tr><tr><td><b>/usr/bin/wget:21329</td><td><b>1</td><td><b>0</td></tr><tr><td>/usr/bin/wget:21442</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21295</td><td>0</td><td>0</td></tr><tr><td>/usr/bin/wget:21512</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21515</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21552</td><td>1</td><td>1</td></tr><tr><td>/usr/bin/wget:21584</td><td>1</td><td>1</td></tr></table> </center>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "[['&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;testcase',\n",
        "  'predicted',\n",
        "  'expected'],\n",
        " ['/usr/bin/wget:21598', 1, 1],\n",
        " ['/usr/bin/wget:21558', 1, 1],\n",
        " ['/usr/bin/wget:21600', 1, 1],\n",
        " ['/usr/bin/wget:21288', 0, 0],\n",
        " ['<b>/usr/bin/wget:21329', '<b>1', '<b>0'],\n",
        " ['/usr/bin/wget:21442', 1, 1],\n",
        " ['/usr/bin/wget:21295', 0, 0],\n",
        " ['/usr/bin/wget:21512', 1, 1],\n",
        " ['/usr/bin/wget:21515', 1, 1],\n",
        " ['/usr/bin/wget:21552', 1, 1],\n",
        " ['/usr/bin/wget:21584', 1, 1]]"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Interesting bugs (re)discovered during these experiments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A format string vulnerability in graphviz, very similar to [CVE-2014-9157](https://security-tracker.debian.org/tracker/CVE-2014-9157) [reported]\n",
      "* [An out-of-bound read using invalid UNICODE strings in libidn](https://bugzilla.redhat.com/show_bug.cgi?id=1197796) (affecting wget at least)\n",
      "* [A few crashes in oggenc](https://bugzilla.redhat.com/show_bug.cgi?id=1185272)\n",
      "* ..."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}